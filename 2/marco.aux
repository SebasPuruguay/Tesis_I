\relax 
\providecommand\hyper@newdestlabel[2]{}
\pp@pagectr{footnote}{2}{13}{12}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}MARCO TEÓRICO}{12}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Antecedentes de la investigación}{12}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Automated recognition of optical image based potato leaf blight diseases using deep learning \citep *{CHAKRABORTY2022101781}}{12}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Planteamiento del Problema y objetivo }{13}{subsubsection.2.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.2}Fundamento Teórico usado por el Autor}{13}{subsubsection.2.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.3}Metodología empleada por los autores}{13}{subsubsection.2.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Metodología propuesta para el modelo (\blx@tocontentsinit {0}\cite {CHAKRABORTY2022101781})}}{14}{figure.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.4}Resultados obtenidos}{14}{subsubsection.2.1.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Arquitectura del modelo ajustado propuesto de VGG16, muestra las disntitas capas (convolucion). Tambien, se mencionana los respectivos tamaños del filtro convolucional (\blx@tocontentsinit {0}\cite {CHAKRABORTY2022101781})}}{15}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Research and Validation of Potato Late Blight Detection Method Based on Deep Learning \citep *{antecedente2}}{15}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}Planteamiento del Problema y objetivo }{15}{subsubsection.2.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.2}Fundamento Teórico usado por el Autor}{16}{subsubsection.2.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  (a) Etapas tempranas de la hoja con tizón tardío en un contexto único. (b) Etapas finales de la hoja con tizón tardío en un contexto único. (c) Etapas tempranas de la hoja con tizón temprano en un contexto único. (d) Etapas finales de la hoja con tizón temprano en un contexto único. (e) Hoja sana en un contexto único. (f) Etapas tempranas de la hoja con tizón tardío en un contexto natural. (g) Etapas finales de la hoja con tizón tardío en un contexto natural. (h) Etapas tempranas de la hoja con tizón temprano en un contexto natural. (i) Etapas finales de la hoja con tizón temprano en un contexto natural. (j) Hoja sana en un contexto natural. (\blx@tocontentsinit {0}\cite {antecedente2})}}{16}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.3}Metodología empleada por los autores}{16}{subsubsection.2.1.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Arquitectura del bot de Azure (\blx@tocontentsinit {0}\cite {antecedente2})}}{17}{figure.caption.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.4}Resultados obtenidos}{17}{subsubsection.2.1.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Arquitectura del modelo final. La estructura del modelo mejorado ShuffleNetV2 2×. Nota: La Etapa 2, la Etapa 3 y la Etapa 4 están compuestas por la unidad base original, con Stride = 1, y la unidad modificada está compuesta por una unidad con Stride = 1 y una unidad con Stride = 2. (1, 1, 2, 1) en la Etapa 2 indica una pila de la unidad (a) con Stride = 2 mejorado, una pila de la unidad (b) con Stride = 1 mejorado, dos pilas de la unidad básica con Stride = 1 original, y una pila de la unidad (c) con Stride = 1 mejorado; (1, 1, 5, 1) en la Etapa 3 indica una pila de la unidad (a) con Stride = 2 mejorado, una pila de la unidad (b) con Stride = 1 mejorado, cinco pilas de la unidad básica con Stride = 1 original, y una pila de la unidad (c) con Stride = 1 mejorado; (1, 1, 1, 1) en la Etapa 4 indica una pila de la unidad (a) con Stride = 2 mejorado, una pila de la unidad (b) con Stride = 1 mejorado, una pila de la unidad básica con Stride = 1 original, y una pila de la unidad (c) con Stride = 1 mejorado. (\blx@tocontentsinit {0}\cite {antecedente2})}}{18}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Interfaz de operación de detección de imágenes. (\blx@tocontentsinit {0}\cite {antecedente2})}}{18}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Supervised Learning-Based Image Classification for the Detection of Late Blight in Potato Crop \citep *{antecedente3}}{19}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.1}Planteamiento del Problema y objetivo }{19}{subsubsection.2.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.2}Fundamento Teórico usado por el Autor}{19}{subsubsection.2.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.3}Metodología empleada por los autores}{19}{subsubsection.2.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Diagrama de la metodologia Flowchart(\blx@tocontentsinit {0}\cite {antecedente3})}}{21}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.4}Resultados obtenidos}{22}{subsubsection.2.1.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Potato Blight Classification Android Application using Deep Learning \citep *{antecedente5}}{22}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.1}Planteamiento del Problema y objetivo }{22}{subsubsection.2.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.2}Fundamento Teórico usado por el Autor}{23}{subsubsection.2.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.3}Metodología empleada por los autores}{23}{subsubsection.2.1.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Metodología (\blx@tocontentsinit {0}\cite {antecedente5})}}{24}{figure.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.4}Resultados obtenidos}{24}{subsubsection.2.1.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Arquitectura del modelo final (\blx@tocontentsinit {0}\cite {antecedente5})}}{24}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Deep Convolutional Neural Networks for image based tomato leaf disease detection \citep *{antecedente6}}{24}{subsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.1}Planteamiento del Problema y objetivo }{25}{subsubsection.2.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.2}Fundamento Teórico usado por el Autor}{25}{subsubsection.2.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.3}Metodología empleada por los autores}{25}{subsubsection.2.1.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Metodología (\blx@tocontentsinit {0}\cite {antecedente6})}}{26}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5.4}Resultados obtenidos}{26}{subsubsection.2.1.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Arquitectura del modelo final (\blx@tocontentsinit {0}\cite {antecedente6})}}{27}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Potato Blight Classification Android Application using Deep Learning \citep *{antecedente7}}{27}{subsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.1}Planteamiento del Problema y objetivo }{28}{subsubsection.2.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.2}Fundamento Teórico usado por el Autor}{28}{subsubsection.2.1.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.3}Metodología empleada por los autores}{28}{subsubsection.2.1.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Metodología (\blx@tocontentsinit {0}\cite {antecedente7})}}{29}{figure.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6.4}Resultados obtenidos}{29}{subsubsection.2.1.6.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Arquitectura del modelo final (\blx@tocontentsinit {0}\cite {antecedente7})}}{29}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}Investigation of Phytophthora Infestans Causing Potato Late Blight Disease: A Review \citep *{antecedente4}}{30}{subsection.2.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.1}Planteamiento del Problema y objetivo }{30}{subsubsection.2.1.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.2}Fundamento Teórico usado por el Autor}{30}{subsubsection.2.1.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.3}Metodología empleada por los autores}{31}{subsubsection.2.1.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Diagrama de la metodologia(\blx@tocontentsinit {0}\cite {antecedente4})}}{31}{figure.caption.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7.4}Resultados obtenidos}{31}{subsubsection.2.1.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Bases Teóricas}{32}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Inteligencia Artificial}{32}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Deep Learning}{32}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Support Vector Machine: A comprehensive survey on support vector machine classification: Applications, challenges and trends \citep *{tecnica3}}{33}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Introducción}{33}{subsubsection.2.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Bases teóricas de SVM}{34}{subsubsection.2.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Hiperplanos de separación(\blx@tocontentsinit {0}\cite {tecnica3})}}{35}{figure.caption.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Clasificador óptimo(\blx@tocontentsinit {0}\cite {tecnica3})}}{37}{figure.caption.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Hiperplanos de margen suave.(\blx@tocontentsinit {0}\cite {tecnica3})}}{38}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Clasificacion no lineal.(\blx@tocontentsinit {0}\cite {tecnica3})}}{39}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.3}Debilidades de SVM}{40}{subsubsection.2.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Complejidad algorítmica}{40}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.4}Implementaciones de SVM}{41}{subsubsection.2.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Resumen de Implementaciones SVM:}{41}{section*.22}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Implementaciones SVM}}{43}{table.caption.26}\protected@file@percent }
\newlabel{tab:svm-implementations}{{2.1}{43}{Implementaciones SVM}{table.caption.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.5}Aplicaciones en problemas del mundo real en Clasificacion de imagenes}{43}{subsubsection.2.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clasificación de Cálculos Renales:}{43}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Detección Temprana de Melanoma:}{43}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reconocimiento de Expresiones Faciales:}{43}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reconocimiento de Gestos de Mano:}{43}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clasificación de Imágenes Hiperespectrales:}{44}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Selección de Características para la Clasificación de Masas Mammográficas:}{44}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clasificación de Imágenes mediante SVM con Kernel de Intersección de Histogramas:}{44}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Decodificación de Códigos QR a Color:}{44}{section*.34}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Número de publicaciones, en capítulos de libros y revistas, por año que contienen los términos de búsqueda SVM y Grandes conjuntos de datos.(\blx@tocontentsinit {0}\cite {tecnica3})}}{45}{figure.caption.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Rendimiento de SVM frente a Aprendizaje profundo(\blx@tocontentsinit {0}\cite {tecnica3})}}{45}{figure.caption.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.6}Conclusiones}{46}{subsubsection.2.2.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Redes neuronales convolucionales: Review of Image Classification Algorithms Based on Convolutional Neural Networks \citep *{tecnica2}}{46}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.1}Visión general de las CNN}{47}{subsubsection.2.2.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Diagrama esquemático del proceso de convolución(\blx@tocontentsinit {0}\cite {tecnica2})}}{48}{figure.caption.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Agrupación máxima y agrupación promedio, no implica relleno cero.(\blx@tocontentsinit {0}\cite {tecnica2})}}{49}{figure.caption.38}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Funciones de pérdida comunes para modelos CNN.}}{50}{table.caption.39}\protected@file@percent }
\newlabel{tab:loss_functions}{{2.2}{50}{Funciones de pérdida comunes para modelos CNN}{table.caption.39}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Métodos de optimización para modelos CNN.}}{51}{table.caption.40}\protected@file@percent }
\newlabel{tab:optimization_methods}{{2.3}{51}{Métodos de optimización para modelos CNN}{table.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.2}Clasificación de imágenes basada en CNN}{52}{subsubsection.2.2.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces La arquitectura de la red LeNet-5. La forma de salida es canal × altura × anchura. Cada capa convolucional Utiliza tallas 5 × 5, relleno 0, zancadas 1. Cada capa de agrupación tiene un tamaño de 2 × 2 y zancadas 2.(\blx@tocontentsinit {0}\cite {tecnica2})}}{53}{figure.caption.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces  La arquitectura de la red VGG-16. Conv: tamaño = 3 × 3, zancada = 1, relleno = 1. Piscina: tamaño = 3 × 3, zancada = 2. (\blx@tocontentsinit {0}\cite {tecnica2})}}{53}{figure.caption.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces  Módulo InceptionV1 a V3 (\blx@tocontentsinit {0}\cite {tecnica2})}}{55}{figure.caption.43}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces  Arquitectura general de InceptionV4. La parte superior de la imagen es la estructura general, la parte inferior de la La imagen es el tallo de la arquitectura. (\blx@tocontentsinit {0}\cite {tecnica2})}}{56}{figure.caption.44}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces Bloques de construcción equivalentes de ResNeXt. (\blx@tocontentsinit {0}\cite {tecnica2})}}{58}{figure.caption.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces  El bloque residual de cuello de botella de MobileNetV2. C es el número de canales y las relaciones de expansión son 6. (\blx@tocontentsinit {0}\cite {tecnica2})}}{60}{figure.caption.46}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces  El bloque residual de cuello de botella de MobileNetV2. C es el número de canales y las relaciones de expansión son 6. (\blx@tocontentsinit {0}\cite {tecnica2})}}{61}{figure.caption.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.3}Conclusiones}{62}{subsubsection.2.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Vision Computer}{63}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Vision Transformer: Explainability of Vision Transformers: A Comprehensive Review and New Perspectives \citep *{tecnica1}}{63}{subsection.2.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.1}Introducción}{64}{subsubsection.2.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.2} Arquitectura de Vision Transformer}{65}{subsubsection.2.2.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces Arquitectura de Vision Transformer (\blx@tocontentsinit {0}\cite {tecnica1})}}{65}{figure.caption.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.3} Explicacion y métodos para Visual Transformer}{65}{subsubsection.2.2.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces  Taxonomía de los métodos de explicabilidad para Transformadores de visión (\blx@tocontentsinit {0}\cite {tecnica1})}}{67}{figure.caption.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.4} Métodos basados en atención}{68}{subsubsection.2.2.6.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Methods for Attention-based Class-specific Multi-modality}}{68}{table.caption.50}\protected@file@percent }
\newlabel{tab:methods}{{2.4}{68}{Methods for Attention-based Class-specific Multi-modality}{table.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces  Visualizaciones específicas de clase de varios métodos basados en la atención, para cada imagen se pueden ver resultados de dos clases diferentes(\blx@tocontentsinit {0}\cite {tecnica1})}}{69}{figure.caption.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.5} Métodos basados en la poda}{69}{subsubsection.2.2.6.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.5}{\ignorespaces  Comparacion de metodos de poda basados en DeiT-S Touvron en 2021 en el conjunto de datos ImageNet}}{70}{table.caption.52}\protected@file@percent }
\newlabel{tab:pruning_comparison}{{2.5}{70}{Comparacion de metodos de poda basados en DeiT-S Touvron en 2021 en el conjunto de datos ImageNet}{table.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces Visualización de tokens desatentos en EViT-DeiT-S con 12 capas; Se puede ver que las fichas de falta de atención se fusionan gradualmente (como se representa mediante áreas enmascaradas) o se eliminan, mientras que las fichas más informativas se conservan. Esto permite a los ViT centrarse en tokens específicos de clase en imágenes, lo que conduce a una mejor interpretabilidad(\blx@tocontentsinit {0}\cite {tecnica1})}}{71}{figure.caption.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.6}Evaluación de explicación}{71}{subsubsection.2.2.6.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces Diferentes criterios para evaluar los métodos de explicabilidad en aplicaciones basadas en la visiónt(\blx@tocontentsinit {0}\cite {tecnica1})}}{73}{figure.caption.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.7}Conclusión}{73}{subsubsection.2.2.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}You Only Look One (YOLO): You Only Look Once: Unified, Real-Time Object Detection \citep *{tecnica4}}{74}{subsection.2.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.1}Introducción}{74}{subsubsection.2.2.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces El sistema de detección YOLO. Procesamiento de imágenes con YOLO es simple y directo. Nuestro sistema (1) cambia de tamaño la imagen de entrada a 448 × 448, (2) ejecuta una única red convolucional en la imagen y (3) establece umbrales para las detecciones resultantes mediante La confianza del modelo.(\blx@tocontentsinit {0}\cite {tecnica4})}}{74}{figure.caption.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.2}Detección unificada}{75}{subsubsection.2.2.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces El sistema aborda la detección como un problema de regresión, donde la imagen se divide en una cuadrícula S × S. Para cada celda de esta cuadrícula, se predicen cuadros delimitadores, confianza asociada con esos cuadros y probabilidades de clase. Estas predicciones se codifican en un tensor con dimensiones S × S × (B x 5 + C). (\blx@tocontentsinit {0}\cite {tecnica4})}}{75}{figure.caption.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.37}{\ignorespaces La red de detección consta de 24 capas convolucionales y 2 capas completamente conectadas. Se utilizan capas convolucionales de 1 × 1 para reducir el espacio de características de las capas anteriores y se preentrenan en la tarea de clasificación de ImageNet a la mitad de la resolución (224 × 224), incrementando la resolución para la detección. (\blx@tocontentsinit {0}\cite {tecnica4})}}{76}{figure.caption.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training}{76}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitaciones de YOLO}{76}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.3}Experimentos}{77}{subsubsection.2.2.7.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.6}{\ignorespaces Comparación de Detectores en Tiempo Real y Menos que en Tiempo Real}}{77}{table.caption.60}\protected@file@percent }
\newlabel{tab:real-time-detectors}{{2.6}{77}{Comparación de Detectores en Tiempo Real y Menos que en Tiempo Real}{table.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.38}{\ignorespaces Análisis de Errores: Fast R-CNN vs. YOLO. Estos gráficos muestran el porcentaje de errores de localización y de fondo en las principales detecciones de varias categorías.}}{78}{figure.caption.61}\protected@file@percent }
\newlabel{fig:error_analysis}{{2.38}{78}{Análisis de Errores: Fast R-CNN vs. YOLO. Estos gráficos muestran el porcentaje de errores de localización y de fondo en las principales detecciones de varias categorías}{figure.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.7}{\ignorespaces Experimentos de combinación de modelos en VOC 2007. Se examina el efecto de combinar varios modelos con la mejor versión de Fast R-CNN.}}{79}{table.caption.62}\protected@file@percent }
\newlabel{table:combination}{{2.7}{79}{Experimentos de combinación de modelos en VOC 2007. Se examina el efecto de combinar varios modelos con la mejor versión de Fast R-CNN}{table.caption.62}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.4}Detección en Tiempo Real en el Mundo Real}{79}{subsubsection.2.2.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.39}{\ignorespaces Resultados cualitativos. YOLO se ejecuta con obras de arte de muestra e imágenes naturales de Internet. Es mayoritariamente exacto, aunque cree que una persona es un avión.(\blx@tocontentsinit {0}\cite {tecnica4})}}{79}{figure.caption.63}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.5}Conclusion}{80}{subsubsection.2.2.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Marco Conceptual}{80}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Vision Computacional \citep *{vc1}}{80}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.40}{\ignorespaces Los otros campos de Vision computacional}}{81}{figure.caption.64}\protected@file@percent }
\newlabel{}{{2.40}{81}{Los otros campos de Vision computacional}{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.1}¿Para qué estudiamos Visión Computacional?}{81}{subsubsection.2.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.2}Modelo de Imagen “Pinhole”}{81}{subsubsection.2.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.41}{\ignorespaces Modelo pinhole}}{82}{figure.caption.65}\protected@file@percent }
\newlabel{}{{2.41}{82}{Modelo pinhole}{figure.caption.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.3}Efectos de Perspectiva}{82}{subsubsection.2.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.42}{\ignorespaces Efectos de Perspectiva}}{82}{figure.caption.66}\protected@file@percent }
\newlabel{}{{2.42}{82}{Efectos de Perspectiva}{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.4}Metodos de Proyección}{82}{subsubsection.2.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simulacion de la visoon humana }{82}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.5}Aberraciones}{83}{subsubsection.2.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Tipos de Aberraciones Geométricas}{83}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.6}¿Qué es una imagen?}{83}{subsubsection.2.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.7}Representación del Color}{83}{subsubsection.2.3.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.43}{\ignorespaces La luz blanca se divide en un espectro de color que contiene 6 regiones: violeta, azul, verde, amarillo, naranja y rojo.}}{84}{figure.caption.69}\protected@file@percent }
\newlabel{}{{2.43}{84}{La luz blanca se divide en un espectro de color que contiene 6 regiones: violeta, azul, verde, amarillo, naranja y rojo}{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Rancha "Phytohpthora Infestans" Tizon Tardio \citep *{prom2}}{84}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.1}Introduccion}{84}{subsubsection.2.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.2}Ciclo de vida y epidemiología del tizón tardío}{85}{subsubsection.2.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.3}Phytophthora infestans - Síntomas de la enfermedad, Modo de infección y propagación}{85}{subsubsection.2.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.44}{\ignorespaces Pérdida de cosechas a nivel nacional debido al tizón tardío de la papa}}{86}{figure.caption.70}\protected@file@percent }
\newlabel{}{{2.44}{86}{Pérdida de cosechas a nivel nacional debido al tizón tardío de la papa}{figure.caption.70}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.4}Conclusion}{86}{subsubsection.2.3.2.4}\protected@file@percent }
\@setckpt{2/marco}{
\setcounter{page}{87}
\setcounter{equation}{1}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{2}
\setcounter{subsubsection}{4}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{44}
\setcounter{table}{7}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{0}
\setcounter{maxnames}{2}
\setcounter{minnames}{1}
\setcounter{maxitems}{999}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{narrator}{0}
\setcounter{savednarrator}{0}
\setcounter{execproducer}{0}
\setcounter{savedexecproducer}{0}
\setcounter{execdirector}{0}
\setcounter{savedexecdirector}{0}
\setcounter{with}{0}
\setcounter{savedwith}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{citation}{0}
\setcounter{savedcitation}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{0}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{section@level}{3}
\setcounter{Item}{40}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{100}
\setcounter{float@type}{4}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{pp@a@footnote}{2}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{nlinenum}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{COOL@strlen}{0}
\setcounter{COOL@strpointer}{0}
\setcounter{COOL@str@index}{0}
\setcounter{COOL@str@start}{0}
\setcounter{COOL@str@end}{0}
\setcounter{COOL@listlen}{0}
\setcounter{COOL@listpointer}{0}
\setcounter{COOL@intsum}{0}
\setcounter{COOL@register@ct}{0}
\setcounter{COOL@register@len}{0}
\setcounter{COOL@ct}{0}
\setcounter{COOL@ct@}{0}
\setcounter{COOL@multideriv}{0}
\setcounter{COOL@row}{0}
\setcounter{COOL@col}{0}
}
